VoiceBox classes

Public-facing API:

audio_service                  <-- audio session establishment/termination/state

Internal classes:

audio_hardware                 <-- audio hardware I/O using RtAudio API
audio_receiver                 <-- ssu stream layer for receiving packets from remote
audio_sender                   <-- ssu stream layer for sending packets to remote
audio_stream                   <-- base class for audio data packets
+--audio_source                <-- base class for audio source chain
|  +--file_source              <-- receive blocks of data from a file stream
|  +--packet_source (network)  <-- receive datagram packets from ssu::stream
|  +--rtaudio_source           <-- capture audio from audio_hardware (as instream)
|  +--jitterbuffer
|  +--packetizer
+--audio_sink                  <-- base class for audio sink chain
   +--packet_sink              <-- send packets as datagrams over ssu::stream
   +--rtaudio_sink             <-- playback audio to audio_hardware (as outstream)
   +--opus_encoder_sink        <-- compress captured packets with OPUS
   +--opus_decoder_sink        <-- decompress received OPUS packets
   +--raw_encoder_sink         <-- encode audio frame as-is
   +--raw_decoder_sink         <-- decode audio frame as-is
   +--jitterbuffer
   +--packetizer

Useful chains of filters:

-- push ----------------->  -- pull --------------------->
rtaudio_source->packetizer->opus_encoder_sink->packet_sink

    push via rtcallback in rtaudio thread:

        rtaudio_source->accept_input(data)

            What happens here is rtaudio_source collects received data into a ringbuffer at
            hardware speed. Some hardware interfaces may call accept_input() at irregular
            intervals with arbitrary buffer size, this source compensates by collecting enough
            data to make up a packet before calling packetizer. This introduces jitter, but
            on average it shall be compensated, since packetizer can be called several times in
            a row, if there's enough data for multiple packets becomes available.

            Packetizer is then called with a fixed-size chunks, comprising a single frame of audio.
            It introduces its own jitter because packetizer uses synchronized_queue and can
            possibly block. @todo Ideally it should use a lock-free queue so that at least the
            rtaudio_source code could continue working if packetizing failed this time.

        packetizer->accept_input(data, size)  <-- interthread sync needed here

    pull via packetizer.on_ready_read() in sendthread:

        packet_sink->produce_output() - send_packet()
        opus_encoder_sink->produce_output() - encode_packet()
        packetizer->produce_output() - get_packet()  <-- interthread sync needed here

-- push ------------------>  -- pull ---------------------->
packet_source->jitterbuffer->opus_decoder_sink->rtaudio_sink

    push via incoming network packet event:

        network_source->accept_input(data)
        jitterbuffer->accept_input() - add_packet(seq, data)  <-- interthread sync needed here

    pull via rtaudio rtcallback:

        rtaudio_sink->produce_output()
        opus_decoder_sink->produce_output() - decode_packet()
        jitterbuffer->produce_output() -> get_packet()  <-- interthread sync needed here

On the edge between sources and sinks usually a thread synchronization primitives are used.
There are two edge classes by default: packetizer and jitterbuffer.

Jitterbuffer also needs to keep track of the current playback timestamp, to discard too old packets
and fill in for missing packets in the queue.

Decoders can either be sources or sinks, depending on where decoding is happening - in push or in
pull threads. It's usually done in pull thread, to decode only what's necessary.
